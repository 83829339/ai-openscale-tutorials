{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Deploy credit risk classification model in Azure Container Instance (ACI)\n\nNow, you're ready to deploy the model as a web service in [Azure Container Instances](https://docs.microsoft.com/azure/container-instances/) (ACI). A web service is an image, in this case a Docker image, that encapsulates the scoring logic and the model itself. \n\nIn this part of the tutorial, you use Azure Machine Learning service to:\n\n> * Set up your testing environment\n> * Retrieve the model from your workspace\n> * Test the model locally\n> * Deploy the model to ACI\n> * Test the deployed model\n\nACI is a great solution for testing and understanding the workflow. For scalable production deployments, consider using Azure Kubernetes Service. For more information, see [how to deploy and where](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Upgrade scikit-learn"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install --upgrade scikit-learn==0.20.2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already up-to-date: scikit-learn==0.20.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.20.2)\nRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-learn==0.20.2) (1.1.0)\nRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-learn==0.20.2) (1.16.2)\n\u001b[33mWARNING: You are using pip version 19.1, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Action: Restart the kernel"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Get scikit-learn 0.20 credit risk model "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!rm -rf german_credit_risk.joblib\n!wget https://github.com/pmservice/ai-openscale-tutorials/raw/master/applications/custom-ml-engine-bluemix/models/credit/german_credit_risk.joblib",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "--2019-05-16 08:27:10--  https://github.com/pmservice/ai-openscale-tutorials/raw/master/applications/custom-ml-engine-bluemix/models/credit/german_credit_risk.joblib\nResolving webproxy (webproxy)... 10.36.68.1\nConnecting to webproxy (webproxy)|10.36.68.1|:3128... connected.\nProxy request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/applications/custom-ml-engine-bluemix/models/credit/german_credit_risk.joblib [following]\n--2019-05-16 08:27:11--  https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/applications/custom-ml-engine-bluemix/models/credit/german_credit_risk.joblib\nConnecting to webproxy (webproxy)|10.36.68.1|:3128... connected.\nProxy request sent, awaiting response... 200 OK\nLength: 9183 (9.0K) [application/octet-stream]\nSaving to: ‘german_credit_risk.joblib’\n\ngerman_credit_risk. 100%[===================>]   8.97K  --.-KB/s    in 0.02s   \n\n2019-05-16 08:27:11 (417 KB/s) - ‘german_credit_risk.joblib’ saved [9183/9183]\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Register model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model_name = \"german_credit_risk\"\nmodel_path=\"german_credit_risk.joblib\"",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "tags": [
          "register model from file"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport urllib.request\n\n# register a model\nfrom azureml.core import Workspace\nws = Workspace.from_config()\n\nfrom azureml.core.model import Model\n\nmodel = Model.register(model_path=model_path,\n                        model_name=model_name,\n                        tags={\"data\": \"german_credit_risk\", \"model\": \"classification\"},\n                        description=\"credit risk sample scikit model\",\n                        workspace=ws)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Registering model german_credit_risk\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws.get_details()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "{'id': '/subscriptions/744bca72-2299-451c-b682-ed6fb75fb671/resourceGroups/ai-ops-squad/providers/Microsoft.MachineLearningServices/workspaces/ai-ops-squad-server',\n 'name': 'ai-ops-squad-server',\n 'location': 'southcentralus',\n 'type': 'Microsoft.MachineLearningServices/workspaces',\n 'workspaceid': '16b06534-668c-4887-aa3c-a10d99eb27e4',\n 'description': '',\n 'friendlyName': '',\n 'creationTime': '2018-10-18T12:12:25.7036291+00:00',\n 'containerRegistry': '/subscriptions/744bca72-2299-451c-b682-ed6fb75fb671/resourcegroups/ai-ops-squad/providers/microsoft.containerregistry/registries/aiopssquadserv4124490709',\n 'keyVault': '/subscriptions/744bca72-2299-451c-b682-ed6fb75fb671/resourcegroups/ai-ops-squad/providers/microsoft.keyvault/vaults/aiopssquadserv3633962467',\n 'applicationInsights': '/subscriptions/744bca72-2299-451c-b682-ed6fb75fb671/resourcegroups/ai-ops-squad/providers/microsoft.insights/components/aiopssquadserv0294391293',\n 'identityPrincipalId': 'e057536e-7de0-4980-8a09-eabf1755973f',\n 'identityTenantId': 'fcf67057-50c9-4ad4-98f3-ffca64add9e9',\n 'identityType': 'SystemAssigned',\n 'storageAccount': '/subscriptions/744bca72-2299-451c-b682-ed6fb75fb671/resourcegroups/ai-ops-squad/providers/microsoft.storage/storageaccounts/aiopssquadserv0098803127'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Set up the environment\n\nStart by setting up a testing environment.\n\n### Import packages\n\nImport the Python packages needed for this tutorial."
    },
    {
      "metadata": {
        "tags": [
          "check version"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.core\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\nimport os \n\nprint(\"Azure ML SDK Version: \", azureml.core.VERSION)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Azure ML SDK Version:  1.0.33\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Retrieve the model\n\nYou registered a model in your workspace in the previous tutorial. Now, load this workspace and download the model to your local directory."
    },
    {
      "metadata": {
        "tags": [
          "load workspace",
          "download model"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws = Workspace.from_config()\nmodel=Model(ws, model_name)\n\nmodel.download(target_dir=os.getcwd(), exist_ok=True)\n\n# verify the downloaded model file\nfile_path = os.path.join(os.getcwd(), \"german_credit_risk.joblib\")\nos.stat(file_path)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "os.stat_result(st_mode=33188, st_ino=13, st_dev=49, st_nlink=1, st_uid=1200, st_gid=1200, st_size=9183, st_atime=0, st_mtime=1557995237, st_ctime=1557995237)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test model locally\n\nBefore deploying, make sure your model is working locally by:\n* Loading test data\n* Predicting test data\n\n### Load test data\n\nLoad the test data from the git repository."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!rm -rf credit_risk_training.csv\n!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/notebooks/data/credit_risk_training.csv",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "--2019-05-16 08:27:17--  https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/notebooks/data/credit_risk_training.csv\nResolving webproxy (webproxy)... 10.36.68.1\nConnecting to webproxy (webproxy)|10.36.68.1|:3128... connected.\nProxy request sent, awaiting response... 200 OK\nLength: 694222 (678K) [text/plain]\nSaving to: ‘credit_risk_training.csv’\n\ncredit_risk_trainin 100%[===================>] 677.95K  2.65MB/s    in 0.3s    \n\n2019-05-16 08:27:18 (2.65 MB/s) - ‘credit_risk_training.csv’ saved [694222/694222]\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\ndata_df = pd.read_csv(\"credit_risk_training.csv\",\n                    dtype={'LoanDuration': int, 'LoanAmount': int, 'InstallmentPercent': int, 'CurrentResidenceDuration': int, 'Age': int, 'ExistingCreditsCount': int, 'Dependents': int})",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Predict test data\n\nFeed the test dataset to the model to get predictions."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pickle\nfrom sklearn.externals import joblib\n\nclf = joblib.load( os.path.join(os.getcwd(), model_path))",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_data = data_df\ntest_data = test_data.drop('Risk', axis=1)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.metrics import accuracy_score\n\nscores = clf['model'].predict_proba(test_data).tolist()\npredictions = clf['postprocessing'](clf['model'].predict(test_data))\n\naccuracy_score(data_df.Risk, predictions)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "0.7784"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Deploy as web service\n\nOnce you've tested the model, deploy the model as a web service hosted in ACI. \n\nTo build the correct environment for ACI, provide the following:\n* A scoring script to show how to use the model\n* An environment file to show what packages need to be installed\n* A configuration file to build the ACI\n* The model you trained before\n\n### Create scoring script\n\nCreate the scoring script, called score.py, used by the web service call to show how to use the model.\n\nYou must include two required functions into the scoring script:\n* The `init()` function, which typically loads the model into a global object. This function is run only once when the Docker container is started. \n\n* The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are supported.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Azure studio-like format"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile score_azure.py\nimport json\nimport numpy as np\nimport os\nimport pandas as pd\nfrom sklearn.externals import joblib\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.model import Model\n\ndef init():\n    global model\n    model_path = Model.get_model_path('german_credit_risk')\n    model = joblib.load(model_path)\n\ndef run(input_data):\n    try:\n        if type(input_data) is str:\n            dict_data = json.loads(input_data)\n        else:\n            dict_data = input_data\n            \n        data = pd.DataFrame.from_dict(dict_data['input'])   \n        predictions = model['postprocessing'](model['model'].predict(data))\n        scores = model['model'].predict_proba(data).tolist()\n        records = []\n        \n        for pred, prob in zip(predictions, scores):\n            records.append({\"Scored Labels\": pred, \"Scored Probabilities\": prob})\n \n        result = {'output': records}\n        \n        return json.dumps(result)\n    except Exception as e:\n        result = str(e)\n        # return error message back to the client\n        return json.dumps({\"error\": result})",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting score_azure.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create environment file\n\nNext, create an environment file, called myenv.yml, that specifies all of the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. This model needs `scikit-learn` and `azureml-sdk`."
    },
    {
      "metadata": {
        "tags": [
          "set conda dependencies"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies \n\nmyenv = CondaDependencies()\nmyenv.add_conda_package(\"scikit-learn==0.20.2\")\n\nwith open(\"myenv.yml\",\"w\") as f:\n    f.write(myenv.serialize_to_string())",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Review the content of the `myenv.yml` file."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open(\"myenv.yml\",\"r\") as f:\n    print(f.read())",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "# Conda environment specification. The dependencies defined in this file will\n# be automatically provisioned for runs with userManagedDependencies=False.\n\n# Details about the Conda environment file format:\n# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n\nname: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\n- pip:\n    # Required packages for AzureML execution, history, and data preparation.\n  - azureml-defaults\n- scikit-learn==0.20.2\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create configuration file\n\nCreate a deployment configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container. While it depends on your model, the default of 1 core and 1 gigabyte of RAM is usually sufficient for many models. If you feel you need more later, you would have to recreate the image and redeploy the service."
    },
    {
      "metadata": {
        "tags": [
          "configure web service",
          "aci"
        ],
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                               memory_gb=1, \n                                               tags={\"data\": \"german credit risk\",  \"method\" : \"sklearn\"}, \n                                               description='Predict Credit Risk with sklearn on Azure Service')",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Deploy in ACI\nEstimated time to complete: **about 7-8 minutes**\n\nConfigure the image and deploy. The following code goes through these steps:\n\n1. Build an image using:\n   * The scoring file (`score.py`)\n   * The environment file (`myenv.yml`)\n   * The model file\n1. Register that image under the workspace. \n1. Send the image to the ACI container.\n1. Start up a container in ACI using the image.\n1. Get the web service HTTP endpoint."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Scoring endpoint creation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.image import ContainerImage\n\n\ndeployment_name = 'credit-risk-prediction'\n\n# configure the image\nimage_config = ContainerImage.image_configuration(execution_script=\"score_azure.py\", \n                                                  runtime=\"python\", \n                                                  conda_file=\"myenv.yml\")\n\nservice_az = Webservice.deploy_from_model(workspace=ws,\n                                       name=deployment_name,\n                                       deployment_config=aciconfig,\n                                       models=[model],\n                                       image_config=image_config)\n\nservice_az.wait_for_deployment(show_output=True)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Creating image\nImage creation operation finished for image credit-risk-prediction:1, operation \"Succeeded\"\nCreating service\nRunning......................\nSucceededACI service creation operation finished, operation \"Succeeded\"\nCPU times: user 1.9 s, sys: 650 ms, total: 2.56 s\nWall time: 6min 55s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(service_az.scoring_uri)",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "http://20.189.138.213:80/score\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test deployed service\n\nEarlier you scored all the test data with the local version of the model. Now, you can test the deployed model with a sample from the test data.  \n\nThe following code goes through these steps:\n1. Send the data as a JSON array to the web service hosted in ACI. \n\n1. Print the returned predictions and plot them along with the input images. Red font and inverse image (white on black) is used to highlight the misclassified samples. \n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "scorig_data = {\"input\":[{\n                            'CheckingStatus': \"0_to_200\", 'LoanDuration': 31, 'CreditHistory': \"credits_paid_to_date\", 'LoanPurpose': \"other\",\n                            'LoanAmount': 1889, 'ExistingSavings': \"100_to_500\",'EmploymentDuration': \"less_1\",'InstallmentPercent': 3,'Sex': \"female\",\n                            'OthersOnLoan': \"none\",'CurrentResidenceDuration': 3, 'OwnsProperty': \"savings_insurance\", 'Age': 32,'InstallmentPlans': \"none\",\n                            'Housing': \"own\",'ExistingCreditsCount': 1,'Job': \"skilled\",'Dependents': 1,'Telephone': \"none\",'ForeignWorker': \"yes\",\n                        },\n                        {\n                            'CheckingStatus': \"no_checking\", 'LoanDuration': 13, 'CreditHistory': \"credits_paid_to_date\", 'LoanPurpose': \"car_new\",\n                            'LoanAmount': 1389, 'ExistingSavings': \"100_to_500\",'EmploymentDuration': \"1_to_4\",'InstallmentPercent': 2,'Sex': \"male\",\n                            'OthersOnLoan': \"none\",'CurrentResidenceDuration': 3, 'OwnsProperty': \"savings_insurance\", 'Age': 25,'InstallmentPlans': \"none\",\n                            'Housing': \"own\",'ExistingCreditsCount': 2,'Job': \"skilled\",'Dependents': 2,'Telephone': \"none\",'ForeignWorker': \"yes\",\n                        }]\n              }",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\n\nheaders = {'Content-Type':'application/json'}\n\n# for AKS deployment you'd need to the service key in the header as well\n# api_key = service.get_key()\n# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n\nresp = requests.post(service_az.scoring_uri, json=scorig_data, headers=headers)\n\nprint(\"POST to url\", service_az.scoring_uri)\nprint(resp.json())",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": "POST to url http://20.189.138.213:80/score\n{\"output\": [{\"Scored Labels\": \"No Risk\", \"Scored Probabilities\": [0.8922524675865824, 0.10774753241341757]}, {\"Scored Labels\": \"No Risk\", \"Scored Probabilities\": [0.8335192848546905, 0.1664807151453095]}]}\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "roastala"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "msauthor": "sgilley",
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}