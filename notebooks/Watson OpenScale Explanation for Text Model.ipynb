{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on generating an explanation for a text-based model on Watson OpenScale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes steps for creating a text-based watson-machine-learning model, creating a subscription, configuring explainability, and finally generating an explanation for a transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "- [1. Setup](#setup)\n",
    "- [2. Creating and deploying a text-based model](#)\n",
    "- [3. Subscriptions](#subscription)\n",
    "- [4. Explainability](#explainability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If using Watson Studio, try running the notebook on atleast 'Default Python 3.5 XS' version for faster results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup\n",
    "\n",
    "### 1.1 Install Watson OpenScale and WML packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-ai-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade watson-machine-learning-client --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Restart the kernel to assure the new libraries are being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Watson Openscale `apikey` by going to the [Bluemix console](https://console.bluemix.net/) and clicking `Manage->Account->Users`. Select `Platform API Keys` from the sidebar and then click the \"Create\" button.\n",
    "\n",
    "One can obtain the Watson OpenScale `instance_id` (guid) by accessing the [cloud console](https://cloud.ibm.com/resources), clicking on `Services` and clicking anywhere on the Watson OpenScale service tile except for the service link and then checking the popping sidebar on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIOS_CREDENTIALS = {\n",
    "    \"instance_guid\": \"*****\",\n",
    "    \"apikey\": \"*****\", \n",
    "    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate or fetch the WML credentials by clicking on `Credentials` in the sidebar of the provisioned WML page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {\n",
    "    \"apikey\": \"*****\",\n",
    "    \"instance_id\": \"*****\",\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating and deploying a text-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is the UCI-ML SMS Spam Collection Dataset which can be found here: https://archive.ics.uci.edu/ml/machine-learning-databases/00228/. It is a binary classification dataset with the labels being 'ham' and 'spam'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data is downloaded and saved as 'SMSSpam.csv' in this step\n",
    "\n",
    "!pip install pandas\n",
    "!rm smsspamcollection.zip\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
    "!unzip smsspamcollection.zip\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"SMSSpamCollection\",sep=\"\\t\",header=None, encoding=\"utf-8\").to_csv(\"SMSSpam.csv\", header=[\"label\", \"text\"], sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm SMSSpamCollection\n",
    "!rm readme\n",
    "!rm smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Skip the pyspark install step below if you are using a Spark kernel on Watson Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark==2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: When running this notebook locally, If the `SparkSession` import fails below, set 'SPARK_HOME' environment variable with the path to `pyspark` installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.csv(path=\"SMSSpam.csv\", header=True, multiLine=True, escape='\"')\n",
    "df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=12345)\n",
    "print(\"Total count of data set: {}\".format(df.count()))\n",
    "print(\"Total count of training data set: {}\".format(train_df.count()))\n",
    "print(\"Total count of test data set: {}\".format(test_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString, CountVectorizer, Tokenizer, IDF, StopWordsRemover\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "\n",
    "stringIndexer_label = StringIndexer(inputCol=\"label\", outputCol=\"label_ix\").fit(df)\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "stopword_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\").setStopWords(stop_words)\n",
    "count = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "nb = GBTClassifier(labelCol=\"label_ix\")\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictionLabel\", labels=stringIndexer_label.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[stringIndexer_label, tokenizer, stopword_remover, count, idf, nb, labelConverter])\n",
    "model = pipeline.fit(train_df)\n",
    "predictions = model.transform(test_df)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label_ix\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Area under ROC curve = %g\" % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "MODEL_NAME = \"Text Binary Classifier\"\n",
    "wml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)\n",
    "\n",
    "model_props = {\n",
    "    wml_client.repository.ModelMetaNames.NAME: \"{}\".format(MODEL_NAME),\n",
    "}\n",
    "\n",
    "# publish model \n",
    "published_model_details = wml_client.repository.store_model(model=model, meta_props=model_props, training_data=train_df, pipeline=pipeline)\n",
    "\n",
    "!rm SMSSpam.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uid = wml_client.repository.get_model_uid(published_model_details)\n",
    "print(model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = wml_client.deployments.create(model_uid, MODEL_NAME + \" deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_url = wml_client.deployments.get_scoring_url(deployment)\n",
    "print(scoring_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Subscriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Configuring AIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale import APIClient\n",
    "from ibm_ai_openscale.engines import WatsonMachineLearningAsset\n",
    "\n",
    "aios_client = APIClient(AIOS_CREDENTIALS)\n",
    "aios_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Please re-run the above cell if it doesn't work the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aios_client.data_mart.bindings.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Subscribe the asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale.supporting_classes import *\n",
    "\n",
    "subscription = aios_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n",
    "    model_uid,\n",
    "    label_column='label',\n",
    "    problem_type=ProblemType.BINARY_CLASSIFICATION,\n",
    "    input_data_type=InputDataType.UNSTRUCTURED_TEXT,\n",
    "    feature_columns = [\"text\"],\n",
    "    categorical_columns = [\"text\"],\n",
    "    prediction_column='predictionLabel',\n",
    "    probability_column='probability'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Get subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aios_client.data_mart.subscriptions.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Score the model and get transaction-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\"\n",
    "payload = {\"fields\": [\"text\"], \"values\": [[text]]}\n",
    "\n",
    "response = wml_client.deployments.score(scoring_url=scoring_url, payload=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Please wait for a few seconds before running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_id = subscription.payload_logging.get_table_content().scoring_id[0]\n",
    "print(transaction_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Configure Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.explainability.enable()\n",
    "subscription.explainability.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Get explanation for the transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.explainability.run(transaction_id, background_mode=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
