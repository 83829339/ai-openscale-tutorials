{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should be run in a Watson Studio project, using Default Spark Python runtime environment. If you are viewing this in Watson Studio and do not see Python 3.6 with Spark in the upper right corner of your screen, please update the runtime now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provision services and configure credentials\n",
    "\n",
    "If you have not already, provision an instance of IBM Watson OpenScale and two instances of IBM Watson Machine Learning using the Cloud catalog.\n",
    "\n",
    "Your Cloud API key can be generated by going to the Users section of the Cloud console. From that page, click your name, scroll down to the API Keys section, and click Create an IBM Cloud API key. Give your key a name and click Create, then copy the created key and paste it below.\n",
    "\n",
    "NOTE: You can also get OpenScale API_KEY using IBM CLOUD CLI.\n",
    "\n",
    "How to install IBM Cloud (bluemix) console: [Instructions](https://console.bluemix.net/docs/cli/reference/ibmcloud/download_cli.html#install_use)\n",
    "\n",
    "<b>How to get api key using console:</b>\n",
    "\n",
    "<li> bx login --sso\n",
    "<li> bx iam api-key-create 'my_key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials for IBM Cloud services\n",
    "\n",
    "### Retrieve your IBM Cloud API key\n",
    "\n",
    "1.\tFrom the IBM Cloud toolbar, click your Account name, such as <Your user name>â€™s Account.\n",
    "1.\tFrom the Manage menu, click Access (IAM).\n",
    "1.\tIn the navigation bar, click IBM Cloud API keys.\n",
    "1.\tClick the Create an IBM Cloud API key button.\n",
    "1.\tType a name and description and then click Save.\n",
    "1.\tCopy the newly created API key and paste it into your notebook in the following **CLOUD_API_KEY** code box, which is the first code box.\n",
    "\n",
    "    Note: replace everything between the two sets of double quotation marks (\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUD_API_KEY = \"YOUR_CLOUD_API_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve your Watson Machine Learning credentials\n",
    "\n",
    "1.\tGo to the IBM Cloud dashboard.\n",
    "1.\tIn the Resource summary section, click Services.\n",
    "1.\tClick Machine Learning-Pre-Prod.\n",
    "1.\tIn the navigation pane, click Service credentials.\n",
    "1.\tClick the New credential button.\n",
    "1.\tCopy your credentials by clicking the copy icon.\n",
    "1.\tReturn to the notebook editor and update the credentials by replacing the sample credentials with your own in the second code box.\n",
    "1.\tRepeat the preceding steps for the prod instance in the third code box.\n",
    "\n",
    "   **Note**: You need to replace everything including the opening bracket ({) and the closing bracket (}).\n",
    "   \n",
    "   **IMPORTANT**: If you are reusing a WML instance that is already bound to Watson OpenScale. Please specify that instance credentials in `PROD_WML_CREDENTIALS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PROD_WML_CREDENTIALS = \"YOUR_PRE_PROD_WML_CREDENTIALS_HERE\"\n",
    "\n",
    "#####################################\n",
    "# Example credentials will look below\n",
    "#####################################\n",
    "\n",
    "# PRE_PROD_WML_CREDENTIALS = {\n",
    "#  \"apikey\": \"*******\",\n",
    "#  \"iam_apikey_description\": \"*******\",\n",
    "#  \"iam_apikey_name\": \"*******\",\n",
    "#  \"iam_role_crn\": \"*******\",\n",
    "#  \"iam_serviceid_crn\": \"*******\",\n",
    "#  \"instance_id\": \"*******\",\n",
    "#  \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD_WML_CREDENTIALS = \"YOUR_PROD_WML_CREDENTIALS_HERE\"\n",
    "\n",
    "#####################################\n",
    "# Example credentials will look below\n",
    "#####################################\n",
    "\n",
    "# PROD_WML_CREDENTIALS = {\n",
    "#  \"apikey\": \"*******\",\n",
    "#  \"iam_apikey_description\": \"*******\",\n",
    "#  \"iam_apikey_name\": \"*******\",\n",
    "#  \"iam_role_crn\": \"*******\",\n",
    "#  \"iam_serviceid_crn\": \"*******\",\n",
    "#  \"instance_id\": \"*******\",\n",
    "#  \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CREDENTIALS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_MY_INTERNAL_POSTGRES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAM_URL=\"https://iam.ng.bluemix.net/oidc/token\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package installation\n",
    "The following opensource packages must be installed into this notebook instance so that they are available to use during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/spark/shared/user-libs/python3.6*\n",
    "\n",
    "!pip install pyspark==2.3 --no-cache | tail -n 1\n",
    "!pip install numpy==1.15.4 --no-cache | tail -n 1\n",
    "!pip install --upgrade ibm-ai-openscale --no-cache | tail -n 1\n",
    "!pip install --upgrade watson-machine-learning-client | tail -n 1\n",
    "!pip install --upgrade SciPy --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data from Github\n",
    "So you don't have to manually generate training data, we've provided a sample and placed it in a publicly available Github repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm german_credit_data_biased_training.csv\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_data_biased_training.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Spark Credit Risk Model to Watson Machine Learning\n",
    "\n",
    "The following cell deploys the Spark version of the German Credit Risk Model to the specified Machine Learning instance in the specified deployment space. You'll notice that this version of the German Credit Risk model has an auc-roc score around 71%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_credit_risk_spark_model(wml_credentials, model_name, deployment_name):\n",
    "\n",
    "    import numpy \n",
    "    numpy.version.version\n",
    "\n",
    "    import pandas as pd\n",
    "    import json\n",
    "\n",
    "    from pyspark import SparkContext, SQLContext\n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.classification import RandomForestClassifier,GBTClassifier\n",
    "    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "    from pyspark.ml.feature import StringIndexer, VectorAssembler, IndexToString\n",
    "    from pyspark.sql.types import StructType, DoubleType, StringType, ArrayType\n",
    "\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark import SparkFiles\n",
    "\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    pd_data = pd.read_csv(\"german_credit_data_biased_training.csv\", sep=\",\", header=0)\n",
    "    spark_df = spark.read.csv(path=\"german_credit_data_biased_training.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "    spark_df.head()\n",
    "\n",
    "    (train_data, test_data) = spark_df.randomSplit([0.9, 0.1], 24)\n",
    "    print(\"Number of records for training: \" + str(train_data.count()))\n",
    "    print(\"Number of records for evaluation: \" + str(test_data.count()))\n",
    "\n",
    "    si_CheckingStatus = StringIndexer(inputCol='CheckingStatus', outputCol='CheckingStatus_IX')\n",
    "    si_CreditHistory = StringIndexer(inputCol='CreditHistory', outputCol='CreditHistory_IX')\n",
    "    si_LoanPurpose = StringIndexer(inputCol='LoanPurpose', outputCol='LoanPurpose_IX')\n",
    "    si_ExistingSavings = StringIndexer(inputCol='ExistingSavings', outputCol='ExistingSavings_IX')\n",
    "    si_EmploymentDuration = StringIndexer(inputCol='EmploymentDuration', outputCol='EmploymentDuration_IX')\n",
    "    si_Sex = StringIndexer(inputCol='Sex', outputCol='Sex_IX')\n",
    "    si_OthersOnLoan = StringIndexer(inputCol='OthersOnLoan', outputCol='OthersOnLoan_IX')\n",
    "    si_OwnsProperty = StringIndexer(inputCol='OwnsProperty', outputCol='OwnsProperty_IX')\n",
    "    si_InstallmentPlans = StringIndexer(inputCol='InstallmentPlans', outputCol='InstallmentPlans_IX')\n",
    "    si_Housing = StringIndexer(inputCol='Housing', outputCol='Housing_IX')\n",
    "    si_Job = StringIndexer(inputCol='Job', outputCol='Job_IX')\n",
    "    si_Telephone = StringIndexer(inputCol='Telephone', outputCol='Telephone_IX')\n",
    "    si_ForeignWorker = StringIndexer(inputCol='ForeignWorker', outputCol='ForeignWorker_IX')\n",
    "    si_Label = StringIndexer(inputCol=\"Risk\", outputCol=\"label\").fit(spark_df)\n",
    "    label_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=si_Label.labels)\n",
    "\n",
    "    va_features = VectorAssembler(\n",
    "    inputCols=[\"CheckingStatus_IX\", \"CreditHistory_IX\", \"LoanPurpose_IX\", \"ExistingSavings_IX\",\n",
    "               \"EmploymentDuration_IX\", \"Sex_IX\", \"OthersOnLoan_IX\", \"OwnsProperty_IX\", \"InstallmentPlans_IX\",\n",
    "               \"Housing_IX\", \"Job_IX\", \"Telephone_IX\", \"ForeignWorker_IX\", \"LoanDuration\", \"LoanAmount\",\n",
    "               \"InstallmentPercent\", \"CurrentResidenceDuration\", \"LoanDuration\", \"Age\", \"ExistingCreditsCount\",\n",
    "               \"Dependents\"], outputCol=\"features\")\n",
    "\n",
    "    classifier=GBTClassifier(featuresCol=\"features\")\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "    stages=[si_CheckingStatus, si_CreditHistory, si_EmploymentDuration, si_ExistingSavings, si_ForeignWorker,\n",
    "            si_Housing, si_InstallmentPlans, si_Job, si_LoanPurpose, si_OthersOnLoan,\n",
    "            si_OwnsProperty, si_Sex, si_Telephone, si_Label, va_features, classifier, label_converter])\n",
    "\n",
    "    model = pipeline.fit(train_data)\n",
    "    predictions = model.transform(test_data)\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "    auc = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(\"Accuracy = %g\" % auc)\n",
    "\n",
    "    from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "    wml_client = WatsonMachineLearningAPIClient(wml_credentials)\n",
    "    print(wml_client.service_instance.get_url())\n",
    "\n",
    "\n",
    "    # Remove existing model and deployment\n",
    "    MODEL_NAME=model_name\n",
    "    DEPLOYMENT_NAME=deployment_name\n",
    "\n",
    "    model_deployment_ids = wml_client.deployments.get_uids()\n",
    "    for deployment_id in model_deployment_ids:\n",
    "        deployment = wml_client.deployments.get_details(deployment_id)\n",
    "        model_id = deployment['entity']['deployable_asset']['guid']\n",
    "        if deployment['entity']['name'] == DEPLOYMENT_NAME:\n",
    "            print('Deleting deployment id', deployment_id)\n",
    "            wml_client.deployments.delete(deployment_id)\n",
    "            print('Deleting model id', model_id)\n",
    "            wml_client.repository.delete(model_id)\n",
    "    wml_client.repository.list_models()\n",
    "    \n",
    "    training_data_reference = {\n",
    "        \"connection\": {\n",
    "            \"db\": \"BLUDB\",\n",
    "            \"host\": \"dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net\",\n",
    "            \"password\": \"khhz72v+6mcwwkfv\",\n",
    "            \"username\": \"cmb91569\"\n",
    "        },\n",
    "        \"name\": \"German credit risk training data\",\n",
    "        \"source\": {\n",
    "            \"tablename\": \"CREDIT_RISK_TRAIN_DATA\",\n",
    "            \"type\": \"db2\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save Model\n",
    "    model_props_rf = {\n",
    "        wml_client.repository.ModelMetaNames.NAME: MODEL_NAME,\n",
    "        wml_client.repository.ModelMetaNames.DESCRIPTION: MODEL_NAME,\n",
    "        wml_client.repository.ModelMetaNames.EVALUATION_METHOD: \"binary\",\n",
    "        wml_client.repository.ModelMetaNames.FRAMEWORK_NAME: \"mllib\",\n",
    "        wml_client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"2.3\",\n",
    "        wml_client.repository.ModelMetaNames.TRAINING_DATA_REFERENCE: training_data_reference,\n",
    "        wml_client.repository.ModelMetaNames.EVALUATION_METRICS: [\n",
    "            {\n",
    "               \"name\": \"areaUnderROC\",\n",
    "               \"value\": auc,\n",
    "               \"threshold\": 0.7\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    published_model_details = wml_client.repository.store_model(model=model, meta_props=model_props_rf, training_data=train_data, pipeline=pipeline)\n",
    "    print(published_model_details)\n",
    "\n",
    "    # List models in the repository\n",
    "    wml_client.repository.list_models()\n",
    "\n",
    "    # Get the model UID\n",
    "    model_uid = wml_client.repository.get_model_uid(published_model_details)\n",
    "    model_uid\n",
    "\n",
    "\n",
    "    # Deploy model\n",
    "    wml_deployments = wml_client.deployments.get_details()\n",
    "    deployment_uid = None\n",
    "    for deployment in wml_deployments['resources']:\n",
    "        if DEPLOYMENT_NAME == deployment['entity']['name']:\n",
    "            deployment_uid = deployment['metadata']['guid']\n",
    "            break\n",
    "\n",
    "    if deployment_uid is None:\n",
    "        print(\"Deploying model...\")\n",
    "\n",
    "        deployment = wml_client.deployments.create(artifact_uid=model_uid, name=DEPLOYMENT_NAME, description=DEPLOYMENT_NAME, asynchronous=False)\n",
    "        deployment_uid = wml_client.deployments.get_uid(deployment)\n",
    "\n",
    "    print(\"Model id: {}\".format(model_uid))\n",
    "    print(\"Deployment id: {}\".format(deployment_uid))\n",
    "\n",
    "    deployment_uid=wml_client.deployments.get_uid(deployment)\n",
    "    deployment_uid\n",
    "\n",
    "    fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\n",
    "    values = [\n",
    "      [\"no_checking\",13,\"credits_paid_to_date\",\"car_new\",1343,\"100_to_500\",\"1_to_4\",2,\"female\",\"none\",3,\"savings_insurance\",46,\"none\",\"own\",2,\"skilled\",1,\"none\",\"yes\"],\n",
    "      [\"no_checking\",24,\"prior_payments_delayed\",\"furniture\",4567,\"500_to_1000\",\"1_to_4\",4,\"male\",\"none\",4,\"savings_insurance\",36,\"none\",\"free\",2,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "      [\"0_to_200\",26,\"all_credits_paid_back\",\"car_new\",863,\"less_100\",\"less_1\",2,\"female\",\"co-applicant\",2,\"real_estate\",38,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "      [\"0_to_200\",14,\"no_credits\",\"car_new\",2368,\"less_100\",\"1_to_4\",3,\"female\",\"none\",3,\"real_estate\",29,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "      [\"0_to_200\",4,\"no_credits\",\"car_new\",250,\"less_100\",\"unemployed\",2,\"female\",\"none\",3,\"real_estate\",23,\"none\",\"rent\",1,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "      [\"no_checking\",17,\"credits_paid_to_date\",\"car_new\",832,\"100_to_500\",\"1_to_4\",2,\"male\",\"none\",2,\"real_estate\",42,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "      [\"no_checking\",33,\"outstanding_credit\",\"appliances\",5696,\"unknown\",\"greater_7\",4,\"male\",\"co-applicant\",4,\"unknown\",54,\"none\",\"free\",2,\"skilled\",1,\"yes\",\"yes\"],\n",
    "      [\"0_to_200\",13,\"prior_payments_delayed\",\"retraining\",1375,\"100_to_500\",\"4_to_7\",3,\"male\",\"none\",3,\"real_estate\",37,\"none\",\"own\",2,\"management_self-employed\",1,\"none\",\"yes\"]\n",
    "    ]\n",
    "\n",
    "    scoring_payload = {\"fields\": fields, \"values\": values}\n",
    "    print(scoring_payload)\n",
    "\n",
    "    # Score the model deployment\n",
    "    credit_risk_scoring_endpoint = None\n",
    "    print(deployment_uid)\n",
    "\n",
    "    for deployment in wml_client.deployments.get_details()['resources']:\n",
    "        if deployment_uid in deployment['metadata']['guid']:\n",
    "            credit_risk_scoring_endpoint = deployment['entity']['scoring_url']\n",
    "\n",
    "    print(credit_risk_scoring_endpoint)\n",
    "\n",
    "    scoring_response = wml_client.deployments.score(credit_risk_scoring_endpoint, scoring_payload)\n",
    "    scoring_response\n",
    "    \n",
    "    return model_uid, deployment_uid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Scikit-Learn Credit Risk Model to Watson Machine Learning\n",
    "\n",
    "The following cell deploys the Scikit-learn version of the German Credit Risk Model to the specified Machine Learning instance in the specified deployment space. This version of the German Credit Risk model has an auc-roc score around 85% and will be called the \"Challenger.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_credit_risk_scikit_model(wml_credentials, model_name, deployment_name):\n",
    "\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import sys\n",
    "    import numpy\n",
    "    import sklearn\n",
    "    import sklearn.ensemble\n",
    "    numpy.set_printoptions(threshold=sys.maxsize)\n",
    "    from sklearn.utils.multiclass import type_of_target\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    from sklearn.metrics import get_scorer\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    data_df=pd.read_csv (\"german_credit_data_biased_training.csv\")\n",
    "\n",
    "    data_df.head()\n",
    "\n",
    "    target_label_name = \"Risk\"\n",
    "    feature_cols= data_df.drop(columns=[target_label_name])\n",
    "    label= data_df[target_label_name]\n",
    "\n",
    "    # Set model evaluation properties\n",
    "    optimization_metric = 'roc_auc'\n",
    "    random_state = 33\n",
    "    cv_num_folds = 3\n",
    "    holdout_fraction = 0.1\n",
    "\n",
    "    if type_of_target(label.values) in ['multiclass', 'binary']:\n",
    "        X_train, X_holdout, y_train, y_holdout = train_test_split(feature_cols, label, test_size=holdout_fraction, random_state=random_state, stratify=label.values)\n",
    "    else:\n",
    "        X_train, X_holdout, y_train, y_holdout = train_test_split(feature_cols, label, test_size=holdout_fraction, random_state=random_state)\n",
    "\n",
    "    # Data preprocessing transformer generation\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('OrdinalEncoder', OrdinalEncoder(categories='auto',dtype=numpy.float64 ))])\n",
    "\n",
    "    numeric_features = feature_cols.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = feature_cols.select_dtypes(include=['object']).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    # Initiate model and create pipeline\n",
    "    model=sklearn.ensemble.gradient_boosting.GradientBoostingClassifier()\n",
    "    gbt_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    model_gbt=gbt_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model_gbt.predict(X_holdout)\n",
    "\n",
    "\n",
    "    # Evaluate model performance on test data and Cross validation\n",
    "    scorer = get_scorer(optimization_metric)\n",
    "    scorer(model_gbt,X_holdout, y_holdout)\n",
    "\n",
    "    # Cross validation -3 folds\n",
    "    cv_results = cross_validate(model_gbt,X_train,y_train, scoring={optimization_metric:scorer})\n",
    "    numpy.mean(cv_results['test_' + optimization_metric])\n",
    "\n",
    "    print(classification_report(y_pred, y_holdout))\n",
    "\n",
    "\n",
    "    # Initiate WML\n",
    "    from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "    wml_client = WatsonMachineLearningAPIClient(wml_credentials)\n",
    "    print(wml_client.service_instance.get_url())\n",
    "\n",
    "\n",
    "    # Remove existing model and deployment\n",
    "    MODEL_NAME=model_name\n",
    "    DEPLOYMENT_NAME=deployment_name\n",
    "\n",
    "    model_deployment_ids = wml_client.deployments.get_uids()\n",
    "    for deployment_id in model_deployment_ids:\n",
    "        deployment = wml_client.deployments.get_details(deployment_id)\n",
    "        model_id = deployment['entity']['deployable_asset']['guid']\n",
    "        if deployment['entity']['name'] == DEPLOYMENT_NAME:\n",
    "            print('Deleting deployment id', deployment_id)\n",
    "            wml_client.deployments.delete(deployment_id)\n",
    "            print('Deleting model id', model_id)\n",
    "            wml_client.repository.delete(model_id)\n",
    "    wml_client.repository.list_models()\n",
    "\n",
    "    # Store Model\n",
    "    model_props_gbt = {\n",
    "        wml_client.repository.ModelMetaNames.NAME: MODEL_NAME,\n",
    "        wml_client.repository.ModelMetaNames.DESCRIPTION: MODEL_NAME,\n",
    "        wml_client.repository.ModelMetaNames.FRAMEWORK_NAME: \"scikit-learn\",\n",
    "        wml_client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"0.19\",\n",
    "        wml_client.repository.ModelMetaNames.RUNTIME_NAME: \"python\"\n",
    "    }\n",
    "\n",
    "    published_model_details = wml_client.repository.store_model(model=model_gbt, meta_props=model_props_gbt, training_data=feature_cols,training_target=label)\n",
    "    print(published_model_details)\n",
    "\n",
    "    # List models in the repository\n",
    "    wml_client.repository.list_models()\n",
    "\n",
    "    # Get the model UID\n",
    "    model_uid = wml_client.repository.get_model_uid(published_model_details)\n",
    "    model_uid\n",
    "\n",
    "\n",
    "    # Deploy model\n",
    "    wml_deployments = wml_client.deployments.get_details()\n",
    "    deployment_uid = None\n",
    "    for deployment in wml_deployments['resources']:\n",
    "        if DEPLOYMENT_NAME == deployment['entity']['name']:\n",
    "            deployment_uid = deployment['metadata']['guid']\n",
    "            break\n",
    "\n",
    "    if deployment_uid is None:\n",
    "        print(\"Deploying model...\")\n",
    "\n",
    "        deployment = wml_client.deployments.create(artifact_uid=model_uid, name=DEPLOYMENT_NAME, description=DEPLOYMENT_NAME, asynchronous=False)\n",
    "        deployment_uid = wml_client.deployments.get_uid(deployment)\n",
    "\n",
    "    print(\"Model id: {}\".format(model_uid))\n",
    "    print(\"Deployment id: {}\".format(deployment_uid))\n",
    "\n",
    "    deployment_uid=wml_client.deployments.get_uid(deployment)\n",
    "    deployment_uid\n",
    "\n",
    "\n",
    "    # Sample scoring\n",
    "    fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\n",
    "    values = [\n",
    "      [\"no_checking\",13,\"credits_paid_to_date\",\"car_new\",1343,\"100_to_500\",\"1_to_4\",2,\"female\",\"none\",3,\"savings_insurance\",46,\"none\",\"own\",2,\"skilled\",1,\"none\",\"yes\"],\n",
    "      [\"no_checking\",24,\"prior_payments_delayed\",\"furniture\",4567,\"500_to_1000\",\"1_to_4\",4,\"male\",\"none\",4,\"savings_insurance\",36,\"none\",\"free\",2,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "      [\"0_to_200\",26,\"all_credits_paid_back\",\"car_new\",863,\"less_100\",\"less_1\",2,\"female\",\"co-applicant\",2,\"real_estate\",38,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "      [\"0_to_200\",14,\"no_credits\",\"car_new\",2368,\"less_100\",\"1_to_4\",3,\"female\",\"none\",3,\"real_estate\",29,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "      [\"0_to_200\",4,\"no_credits\",\"car_new\",250,\"less_100\",\"unemployed\",2,\"female\",\"none\",3,\"real_estate\",23,\"none\",\"rent\",1,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "      [\"no_checking\",17,\"credits_paid_to_date\",\"car_new\",832,\"100_to_500\",\"1_to_4\",2,\"male\",\"none\",2,\"real_estate\",42,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "      [\"no_checking\",33,\"outstanding_credit\",\"appliances\",5696,\"unknown\",\"greater_7\",4,\"male\",\"co-applicant\",4,\"unknown\",54,\"none\",\"free\",2,\"skilled\",1,\"yes\",\"yes\"],\n",
    "      [\"0_to_200\",13,\"prior_payments_delayed\",\"retraining\",1375,\"100_to_500\",\"4_to_7\",3,\"male\",\"none\",3,\"real_estate\",37,\"none\",\"own\",2,\"management_self-employed\",1,\"none\",\"yes\"]\n",
    "    ]\n",
    "\n",
    "    payload_scoring = {\"fields\": fields,\"values\": values}\n",
    "    print(payload_scoring)\n",
    "\n",
    "    credit_risk_scoring_endpoint = None\n",
    "    print(deployment_uid)\n",
    "\n",
    "    for deployment in wml_client.deployments.get_details()['resources']:\n",
    "        if deployment_uid in deployment['metadata']['guid']:\n",
    "            credit_risk_scoring_endpoint = deployment['entity']['scoring_url']\n",
    "\n",
    "    print(credit_risk_scoring_endpoint)\n",
    "\n",
    "    scoring_response = wml_client.deployments.score(credit_risk_scoring_endpoint, payload_scoring)\n",
    "    scoring_response\n",
    "\n",
    "    return model_uid, deployment_uid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the models\n",
    "\n",
    "The following cells will deploy both the PreProd and Challenger models into the WML instance that is designated as Pre-Production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PROD_MODEL_NAME=\"German Credit Risk Model - PreProd\"\n",
    "PRE_PROD_DEPLOYMENT_NAME=\"German Credit Risk Model - PreProd\"\n",
    "\n",
    "PRE_PROD_CHALLENGER_MODEL_NAME=\"German Credit Risk Model - Challenger\"\n",
    "PRE_PROD_CHALLENGER_DEPLOYMENT_NAME=\"German Credit Risk Model - Challenger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prod_model_uid, pre_prod_deployment_uid = deploy_credit_risk_spark_model(PRE_PROD_WML_CREDENTIALS, PRE_PROD_MODEL_NAME, PRE_PROD_DEPLOYMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_model_uid, challenger_deployment_uid = deploy_credit_risk_scikit_model(PRE_PROD_WML_CREDENTIALS, PRE_PROD_CHALLENGER_MODEL_NAME, PRE_PROD_CHALLENGER_DEPLOYMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure OpenScale \n",
    "The notebook will now import the necessary libraries and set up a Python OpenScale client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale import APIClient\n",
    "from ibm_ai_openscale.engines import *\n",
    "from ibm_ai_openscale.utils import *\n",
    "from ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\n",
    "from ibm_ai_openscale.supporting_classes.enums import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Watson OpenScale GUID\n",
    "Each instance of OpenScale has a unique ID. We can get this value using the Cloud API key specified at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale.utils import get_instance_guid\n",
    "\n",
    "\n",
    "WOS_GUID = get_instance_guid(api_key=CLOUD_API_KEY)\n",
    "WOS_CREDENTIALS = {\n",
    "    \"instance_guid\": WOS_GUID,\n",
    "    \"apikey\": CLOUD_API_KEY,\n",
    "    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n",
    "}\n",
    "\n",
    "if WOS_GUID is None:\n",
    "    print('Watson OpenScale GUID NOT FOUND')\n",
    "else:\n",
    "    print(WOS_GUID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client = APIClient(aios_credentials=WOS_CREDENTIALS)\n",
    "ai_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schema and datamart\n",
    "\n",
    "### Set up datamart\n",
    "Watson OpenScale uses a database to store payload logs and calculated metrics. If database credentials were not supplied above, the notebook will use the free, internal lite database. If database credentials were supplied, the datamart will be created there unless there is an existing datamart and the KEEP_MY_INTERNAL_POSTGRES variable is set to True. If an OpenScale datamart exists in Db2 or PostgreSQL, the existing datamart will be used and no data will be overwritten.\n",
    "\n",
    "Prior instances of the German Credit model will be removed from OpenScale monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_mart_details = ai_client.data_mart.get_details()\n",
    "    if 'internal_database' in data_mart_details and data_mart_details['internal_database']:\n",
    "        if KEEP_MY_INTERNAL_POSTGRES:\n",
    "            print('Using existing internal datamart.')\n",
    "        else:\n",
    "            if DB_CREDENTIALS is None:\n",
    "                print('No postgres credentials supplied. Using existing internal datamart')\n",
    "            else:\n",
    "                print('Switching to external datamart')\n",
    "                ai_client.data_mart.delete(force=True)\n",
    "                ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n",
    "    else:\n",
    "        print('Using existing external datamart')\n",
    "except:\n",
    "    if DB_CREDENTIALS is None:\n",
    "        print('Setting up internal datamart')\n",
    "        ai_client.data_mart.setup(internal_db=True)\n",
    "    else:\n",
    "        print('Setting up external datamart')\n",
    "        try:\n",
    "            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n",
    "        except:\n",
    "            print('Setup failed, trying Db2 setup')\n",
    "            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS, schema=DB_CREDENTIALS['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mart_details = ai_client.data_mart.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mart_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bind WML machine learning instance as Pre-Prod\n",
    "\n",
    "Watson OpenScale needs to be bound to the Watson Machine Learning instance to capture payload data into and out of the model. If a binding with name \"WML Pre-Prod\" already exists, this code will delete that binding a create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bindings = ai_client.data_mart.bindings.get_details()['service_bindings']\n",
    "existing_binding = False\n",
    "for binding in all_bindings:\n",
    "    binding_uid = binding['metadata']['guid']\n",
    "    if binding['metadata']['guid'] == PRE_PROD_WML_CREDENTIALS['instance_id']:\n",
    "        existing_binding = True\n",
    "        break\n",
    "\n",
    "if not existing_binding:\n",
    "    binding_uid = ai_client.data_mart.bindings.add('WML Pre-Prod', WatsonMachineLearningInstance(PRE_PROD_WML_CREDENTIALS))\n",
    "    \n",
    "bindings_details = ai_client.data_mart.bindings.get_details()\n",
    "ai_client.data_mart.bindings.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(binding_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client.data_mart.bindings.get_details(binding_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client.data_mart.bindings.list_assets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an IAM token\n",
    "\n",
    "The following is a function that will generate an IAM access token used to interact with the Watson OpenScale APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import base64\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_access_token():\n",
    "    headers={}\n",
    "    headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n",
    "    headers[\"Accept\"] = \"application/json\"\n",
    "    auth = HTTPBasicAuth(\"bx\", \"bx\")\n",
    "    data = {\n",
    "        \"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\",\n",
    "        \"apikey\": CLOUD_API_KEY\n",
    "    }\n",
    "    response = requests.post(IAM_URL, data=data, headers=headers, auth=auth)\n",
    "    json_data = response.json()\n",
    "    iam_access_token = json_data['access_token']\n",
    "    return iam_access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch the binding as pre-production \n",
    "\n",
    "We patch the binding created previously as `pre_production`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "payload = [\n",
    " {\n",
    "   \"op\": \"replace\",\n",
    "   \"path\": \"/operational_space_id\",\n",
    "   \"value\": \"pre_production\"\n",
    " }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_PROVIDER_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/service_providers/{1}\".format(WOS_GUID, binding_uid)\n",
    "\n",
    "response = requests.patch(SERVICE_PROVIDER_URL, json=payload, headers=headers)\n",
    "json_data = response.json()\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscriptions\n",
    "### Remove existing PreProd and Challenger credit risk subscriptions\n",
    "This code removes previous subscriptions to the German Credit model to refresh the monitors with the new model and new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "for subscription in subscriptions_uids:\n",
    "    sub_name = ai_client.data_mart.subscriptions.get_details(subscription)['entity']['asset']['name']\n",
    "    if sub_name == PRE_PROD_MODEL_NAME or sub_name == PRE_PROD_CHALLENGER_MODEL_NAME:\n",
    "        ai_client.data_mart.subscriptions.delete(subscription)\n",
    "        print('Deleted existing subscription for', sub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prod_subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n",
    "    pre_prod_model_uid,\n",
    "    binding_uid=binding_uid,\n",
    "    problem_type=ProblemType.BINARY_CLASSIFICATION,\n",
    "    input_data_type=InputDataType.STRUCTURED,\n",
    "    label_column='Risk',\n",
    "    prediction_column='predictedLabel',\n",
    "    probability_column='probability',\n",
    "    feature_columns = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"],\n",
    "    categorical_columns = [\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"]\n",
    "))\n",
    "\n",
    "if pre_prod_subscription is None:\n",
    "    print('Subscription already exists; get the existing one')\n",
    "    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "    for sub in subscriptions_uids:\n",
    "        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == PRE_PROD_MODEL_NAME:\n",
    "            pre_prod_subscription = ai_client.data_mart.subscriptions.get(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n",
    "    challenger_model_uid,\n",
    "    binding_uid=binding_uid,\n",
    "    problem_type=ProblemType.BINARY_CLASSIFICATION,\n",
    "    input_data_type=InputDataType.STRUCTURED,\n",
    "    label_column='Risk',\n",
    "    prediction_column='prediction',\n",
    "    probability_column='probability',\n",
    "    feature_columns = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"],\n",
    "    categorical_columns = [\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"]\n",
    "))\n",
    "\n",
    "if challenger_subscription is None:\n",
    "    print('Subscription already exists; get the existing one')\n",
    "    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "    for sub in subscriptions_uids:\n",
    "        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == PRE_PROD_CHALLENGER_MODEL_NAME:\n",
    "            challenger_subscription = ai_client.data_mart.subscriptions.get(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client.data_mart.subscriptions.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prod_subscription.uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_subscription.uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch the training data reference to the challenger subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "training_data_reference = {\n",
    "  \"connection\": {\n",
    "    \"connection_string\": \"jdbc:db2://dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net:50000/BLUDB:retrieveMessagesFromServerOnGetMessage=true;\",\n",
    "    \"database_name\": \"BLUDB\",\n",
    "    \"hostname\": \"dashdb-txn-sbox-yp-dal09-03.services.dal.bluemix.net\",\n",
    "    \"password\": \"khhz72v+6mcwwkfv\",\n",
    "    \"username\": \"cmb91569\"\n",
    "  },\n",
    "  \"location\": {\n",
    "    \"schema_name\": \"CMB91569\",\n",
    "    \"table_name\": \"CREDIT_RISK_TRAIN_DATA\"\n",
    "  },\n",
    "  \"name\": \"German credit risk training data\",\n",
    "  \"type\": \"db2\"\n",
    "}\n",
    "\n",
    "payload = [\n",
    " {\n",
    "   \"op\": \"replace\",\n",
    "   \"path\": \"/asset_properties/training_data_reference\",\n",
    "   \"value\": training_data_reference\n",
    " }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSCRIPTION_URL = WOS_CREDENTIALS[\"url\"] + \"/v1/data_marts/{0}/service_bindings/{1}/subscriptions/{2}\".format(WOS_GUID, binding_uid, challenger_subscription.uid)\n",
    "\n",
    "response = requests.patch(SUBSCRIPTION_URL, json=payload, headers=headers)\n",
    "json_data = response.json()\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the model so we can configure monitors\n",
    "Now that the WML service has been bound and the subscription has been created, we need to send a request to the model before we configure OpenScale. This allows OpenScale to create a payload log in the datamart with the correct schema, so it can capture data coming into and out of the model. First, the code gets the model deployment's endpoint URL, and then sends a few records for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\n",
    "values = [\n",
    "  [\"no_checking\",13,\"credits_paid_to_date\",\"car_new\",1343,\"100_to_500\",\"1_to_4\",2,\"female\",\"none\",3,\"savings_insurance\",46,\"none\",\"own\",2,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",24,\"prior_payments_delayed\",\"furniture\",4567,\"500_to_1000\",\"1_to_4\",4,\"male\",\"none\",4,\"savings_insurance\",36,\"none\",\"free\",2,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",26,\"all_credits_paid_back\",\"car_new\",863,\"less_100\",\"less_1\",2,\"female\",\"co-applicant\",2,\"real_estate\",38,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",14,\"no_credits\",\"car_new\",2368,\"less_100\",\"1_to_4\",3,\"female\",\"none\",3,\"real_estate\",29,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",4,\"no_credits\",\"car_new\",250,\"less_100\",\"unemployed\",2,\"female\",\"none\",3,\"real_estate\",23,\"none\",\"rent\",1,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",17,\"credits_paid_to_date\",\"car_new\",832,\"100_to_500\",\"1_to_4\",2,\"male\",\"none\",2,\"real_estate\",42,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",33,\"outstanding_credit\",\"appliances\",5696,\"unknown\",\"greater_7\",4,\"male\",\"co-applicant\",4,\"unknown\",54,\"none\",\"free\",2,\"skilled\",1,\"yes\",\"yes\"],\n",
    "  [\"0_to_200\",13,\"prior_payments_delayed\",\"retraining\",1375,\"100_to_500\",\"4_to_7\",3,\"male\",\"none\",3,\"real_estate\",37,\"none\",\"own\",2,\"management_self-employed\",1,\"none\",\"yes\"]\n",
    "]\n",
    "\n",
    "payload_scoring = {\"fields\": fields,\"values\": values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "wml_client = WatsonMachineLearningAPIClient(PRE_PROD_WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prod_credit_risk_scoring_endpoint = None\n",
    "print(pre_prod_deployment_uid)\n",
    "\n",
    "for deployment in wml_client.deployments.get_details()['resources']:\n",
    "    if pre_prod_deployment_uid in deployment['metadata']['guid']:\n",
    "        pre_prod_credit_risk_scoring_endpoint = deployment['entity']['scoring_url']\n",
    "        \n",
    "print(pre_prod_credit_risk_scoring_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_response = wml_client.deployments.score(pre_prod_credit_risk_scoring_endpoint, payload_scoring)\n",
    "\n",
    "print('Single record scoring result:', '\\n fields:', scoring_response['fields'], '\\n values: ', scoring_response['values'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "pre_prod_subscription.payload_logging.get_records_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_credit_risk_scoring_endpoint = None\n",
    "print(challenger_deployment_uid)\n",
    "\n",
    "for deployment in wml_client.deployments.get_details()['resources']:\n",
    "    if challenger_deployment_uid in deployment['metadata']['guid']:\n",
    "        challenger_credit_risk_scoring_endpoint = deployment['entity']['scoring_url']\n",
    "        \n",
    "print(challenger_credit_risk_scoring_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_response = wml_client.deployments.score(challenger_credit_risk_scoring_endpoint, payload_scoring)\n",
    "\n",
    "print('Single record scoring result:', '\\n fields:', scoring_response['fields'], '\\n values: ', scoring_response['values'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "challenger_subscription.payload_logging.get_records_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality monitoring\n",
    "\n",
    "## Enable quality monitoring\n",
    "The code below waits ten seconds to allow the payload logging table to be set up before it begins enabling monitors. First, it turns on the quality (accuracy) monitor and sets an alert threshold of 80%. OpenScale will show an alert on the dashboard if the model accuracy measurement (area under the curve, in the case of a binary classifier) falls below this threshold.\n",
    "\n",
    "The second paramater supplied, min_records, specifies the minimum number of feedback records OpenScale needs before it calculates a new measurement. The quality monitor runs hourly, but the accuracy reading in the dashboard will not change until an additional 50 feedback records have been added, via the user interface, the Python client, or the supplied feedback endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "pre_prod_subscription.quality_monitoring.enable(threshold=0.8, min_records=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "challenger_subscription.quality_monitoring.enable(threshold=0.8, min_records=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness, drift monitoring and explanations \n",
    "\n",
    "## Fairness configuration\n",
    "The code below configures fairness monitoring for our model. It turns on monitoring for two features, Sex and Age. In each case, we must specify:\n",
    "\n",
    "Which model feature to monitor\n",
    "One or more majority groups, which are values of that feature that we expect to receive a higher percentage of favorable outcomes\n",
    "One or more minority groups, which are values of that feature that we expect to receive a higher percentage of unfavorable outcomes\n",
    "The threshold at which we would like OpenScale to display an alert if the fairness measurement falls below (in this case, 80%)\n",
    "Additionally, we must specify which outcomes from the model are favourable outcomes, and which are unfavourable. We must also provide the number of records OpenScale will use to calculate the fairness score. In this case, OpenScale's fairness monitor will run hourly, but will not calculate a new fairness rating until at least 100 records have been added. Finally, to calculate fairness, OpenScale must perform some calculations on the training data, so we provide the dataframe containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_data = pd.read_csv(\"german_credit_data_biased_training.csv\", sep=\",\", header=0)\n",
    "\n",
    "pre_prod_subscription.fairness_monitoring.enable(\n",
    "            features=[\n",
    "                Feature(\"Sex\", majority=['male'], minority=['female'], threshold=0.80),\n",
    "                Feature(\"Age\", majority=[[26,74]], minority=[[19,25]], threshold=0.80)\n",
    "            ],\n",
    "            favourable_classes=['No Risk'],\n",
    "            unfavourable_classes=['Risk'],\n",
    "            min_records=100,\n",
    "            training_data=pd_data\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_subscription.fairness_monitoring.enable(\n",
    "            features=[\n",
    "                Feature(\"Sex\", majority=['male'], minority=['female'], threshold=0.80),\n",
    "                Feature(\"Age\", majority=[[26,74]], minority=[[19,25]], threshold=0.80)\n",
    "            ],\n",
    "            favourable_classes=['No Risk'],\n",
    "            unfavourable_classes=['Risk'],\n",
    "            min_records=100,\n",
    "            training_data=pd_data\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drift configuration\n",
    "\n",
    "Enable the drift configuration for both the subscription created with a threshold of 10% and minimal sample as 100 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prod_subscription.drift_monitoring.enable(threshold=0.10, min_records=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_status = None\n",
    "while drift_status != 'finished':\n",
    "    drift_details = pre_prod_subscription.drift_monitoring.get_details()\n",
    "    drift_status = drift_details['parameters']['config_status']['state']\n",
    "    if drift_status != 'finished':\n",
    "        print(datetime.utcnow().strftime('%H:%M:%S'), drift_status)\n",
    "        time.sleep(30)\n",
    "print(drift_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_subscription.drift_monitoring.enable(threshold=0.10, min_records=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_status = None\n",
    "while drift_status != 'finished':\n",
    "    drift_details = challenger_subscription.drift_monitoring.get_details()\n",
    "    drift_status = drift_details['parameters']['config_status']['state']\n",
    "    if drift_status != 'finished':\n",
    "        print(datetime.utcnow().strftime('%H:%M:%S'), drift_status)\n",
    "        time.sleep(30)\n",
    "print(drift_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Explainability\n",
    "Finally, we provide OpenScale with the training data to enable and configure the explainability features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale.supporting_classes import *\n",
    "\n",
    "pre_prod_subscription.explainability.enable(training_data=pd_data)\n",
    "challenger_subscription.explainability.enable(training_data=pd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable MRM \n",
    "\n",
    "We enable the MRM configuration for both the subscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "payload = {\n",
    "  \"data_mart_id\": WOS_GUID,\n",
    "  \"monitor_definition_id\": \"mrm\",\n",
    "  \"target\": {\n",
    "    \"target_id\": pre_prod_subscription.uid,\n",
    "    \"target_type\": \"subscription\"\n",
    "  },\n",
    "  \"parameters\": {\n",
    "  },\n",
    "  \"managed_by\": \"user\"\n",
    "}\n",
    "\n",
    "MONITOR_INSTANCES_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/monitor_instances\".format(WOS_GUID)\n",
    "\n",
    "response = requests.post(MONITOR_INSTANCES_URL, json=payload, headers=headers)\n",
    "json_data = response.json()\n",
    "print(json_data)\n",
    "if \"metadata\" in json_data and \"id\" in json_data[\"metadata\"]:\n",
    "    pre_prod_mrm_instance_id = json_data[\"metadata\"][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "payload = {\n",
    "  \"data_mart_id\": WOS_GUID,\n",
    "  \"monitor_definition_id\": \"mrm\",\n",
    "  \"target\": {\n",
    "    \"target_id\": challenger_subscription.uid,\n",
    "    \"target_type\": \"subscription\"\n",
    "  },\n",
    "  \"parameters\": {\n",
    "  },\n",
    "  \"managed_by\": \"user\"\n",
    "}\n",
    "\n",
    "MONITOR_INSTANCES_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/monitor_instances\".format(WOS_GUID)\n",
    "\n",
    "response = requests.post(MONITOR_INSTANCES_URL, json=payload, headers=headers)\n",
    "json_data = response.json()\n",
    "print(json_data)\n",
    "if \"metadata\" in json_data and \"id\" in json_data[\"metadata\"]:\n",
    "    challenger_mrm_instance_id = json_data[\"metadata\"][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test data sets from the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = pd_data[1:201]\n",
    "test_data_1.to_csv(\"german_credit_risk_test_data_1.csv\", encoding=\"utf-8\", index=False)\n",
    "test_data_2 = pd_data[201:401]\n",
    "test_data_2.to_csv(\"german_credit_risk_test_data_2.csv\", encoding=\"utf-8\", index=False)\n",
    "test_data_3 = pd_data[401:601]\n",
    "test_data_3.to_csv(\"german_credit_risk_test_data_3.csv\", encoding=\"utf-8\", index=False)\n",
    "test_data_4 = pd_data[601:801]\n",
    "test_data_4.to_csv(\"german_credit_risk_test_data_4.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to upload, evaluate and check the status of the evaluation\n",
    "\n",
    "This function will upload the test data CSV and trigger the risk evaluation. It will iterate and check the status of the evaluation until its finished with a finite wait duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_and_evaluate(file_name, mrm_instance_id):\n",
    "    \n",
    "    print(\"Running upload and evaluate for {}\".format(file_name))\n",
    "    import json\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "\n",
    "    status = None\n",
    "    monitoring_run_id = None\n",
    "    GET_UPLOAD_AND_EVALUATION_STATUS_RETRIES = 32\n",
    "    GET_UPLOAD_AND_EVALUATION_STATUS_INTERVAL = 10\n",
    "    \n",
    "    if file_name is not None:\n",
    "        \n",
    "        headers = {}\n",
    "        headers[\"Content-Type\"] = \"text/csv\"\n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "        \n",
    "        POST_EVALUATIONS_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/monitoring_services/mrm/monitor_instances/{1}/risk_evaluations?test_data_set_name={2}\".format(WOS_GUID, mrm_instance_id, file_name)\n",
    "\n",
    "        with open(file_name) as file:\n",
    "            f = file.read()\n",
    "            b = bytearray(f, 'utf-8')\n",
    "\n",
    "        response = requests.post(POST_EVALUATIONS_URL, data=bytes(b), headers=headers)\n",
    "        if response.ok is False:\n",
    "            print(\"Upload and evalaute for {0} failed with {1}: {2}\".format(file_name, response.status_code, response.reason))\n",
    "            return\n",
    "        \n",
    "        headers = {}\n",
    "        headers[\"Content-Type\"] = \"application/json\"\n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "        GET_EVALUATIONS_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/monitoring_services/mrm/monitor_instances/{1}/risk_evaluations\".format(WOS_GUID, mrm_instance_id)\n",
    "        \n",
    "        for i in range(GET_UPLOAD_AND_EVALUATION_STATUS_RETRIES):\n",
    "        \n",
    "            response = requests.get(GET_EVALUATIONS_URL, headers=headers)\n",
    "            if response.ok is False:\n",
    "                print(\"Getting status of upload and evalaute for {0} failed with {1}: {2}\".format(file_name, response.status_code, response.reason))\n",
    "                return\n",
    "\n",
    "            response = json.loads(response.text)\n",
    "            if \"metadata\" in response and \"id\" in response[\"metadata\"]:\n",
    "                monitoring_run_id = response[\"metadata\"][\"id\"]\n",
    "            if \"entity\" in response and \"status\" in response[\"entity\"]:\n",
    "                status = response[\"entity\"][\"status\"][\"state\"]\n",
    "            \n",
    "            if status is not None:\n",
    "                print(datetime.utcnow().strftime('%H:%M:%S'), status.lower())\n",
    "                if status.lower() in [\"finished\", \"completed\"]:\n",
    "                    break\n",
    "                elif \"error\"in status.lower():\n",
    "                    print(response)\n",
    "                    break\n",
    "\n",
    "            time.sleep(GET_UPLOAD_AND_EVALUATION_STATUS_INTERVAL)\n",
    "\n",
    "    return status, monitoring_run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Risk Evaluations\n",
    "\n",
    "We now start performing evaluations of smaller data sets against both the PreProd and Challenger subscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_and_evaluate(\"german_credit_risk_test_data_1.csv\", pre_prod_mrm_instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_and_evaluate(\"german_credit_risk_test_data_2.csv\", pre_prod_mrm_instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_and_evaluate(\"german_credit_risk_test_data_3.csv\", pre_prod_mrm_instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_and_evaluate(\"german_credit_risk_test_data_4.csv\", pre_prod_mrm_instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_and_evaluate(\"german_credit_risk_test_data_1.csv\", challenger_mrm_instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_and_evaluate(\"german_credit_risk_test_data_2.csv\", challenger_mrm_instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_and_evaluate(\"german_credit_risk_test_data_3.csv\", challenger_mrm_instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_and_evaluate(\"german_credit_risk_test_data_4.csv\", challenger_mrm_instance_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Model Risk Management UI\n",
    "\n",
    "Here is a quick recap of what we have done so far.\n",
    "\n",
    "1. We've deployed two Credit Risk Model to a WML instance that is designated as Pre-Production\n",
    "2. We've created subscriptions of these two model deployments in OpenScale\n",
    "3. Configured all monitors supported by OpenScale for these subscriptions\n",
    "4. We've performed a few risk evaluations against both these susbscription with the same set of test data\n",
    "\n",
    "Now, please explore the Model Risk Management UI to visualize the results, compare the performance of models, download the evaluation report as PDF\n",
    "\n",
    "Link to OpenScale : https://aiopenscale.cloud.ibm.com/aiopenscale/insights?mrm=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promote pre-production model to production \n",
    "\n",
    "After you have reviewed the evaluation results of the PreProd Vs Challenger and if you make the decision to promote the PreProd model to Production, the first thing you need to do is to deploy the model into a WML instance that is designated as Production instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model to production WML instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD_MODEL_NAME=\"German Credit Risk Model - Prod\"\n",
    "PROD_DEPLOYMENT_NAME=\"German Credit Risk Model - Prod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_model_uid, prod_deployment_uid = deploy_credit_risk_spark_model(PROD_WML_CREDENTIALS, PROD_MODEL_NAME, PROD_DEPLOYMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bind WML machine learning instance as Prod\n",
    "\n",
    "Watson OpenScale needs to be bound to the Watson Machine Learning instance to capture payload data into and out of the model. If a binding with name \"WML Prod\" already exists, this code will delete that binding a create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bindings = ai_client.data_mart.bindings.get_details()['service_bindings']\n",
    "existing_binding = False\n",
    "for binding in all_bindings:\n",
    "    binding_uid = binding['metadata']['guid']\n",
    "    if binding['metadata']['guid'] == PROD_WML_CREDENTIALS['instance_id']:\n",
    "        existing_binding = True\n",
    "        break\n",
    "\n",
    "if not existing_binding:\n",
    "    binding_uid = ai_client.data_mart.bindings.add('WML Prod', WatsonMachineLearningInstance(PROD_WML_CREDENTIALS))\n",
    "    \n",
    "bindings_details = ai_client.data_mart.bindings.get_details()\n",
    "ai_client.data_mart.bindings.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(binding_uid)\n",
    "ai_client.data_mart.bindings.get_details(binding_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client.data_mart.bindings.list_assets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch binding as production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "payload = [\n",
    " {\n",
    "   \"op\": \"replace\",\n",
    "   \"path\": \"/operational_space_id\",\n",
    "   \"value\": \"production\"\n",
    " }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_PROVIDER_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/service_providers/{1}\".format(WOS_GUID, binding_uid)\n",
    "response = requests.patch(SERVICE_PROVIDER_URL, json=payload, headers=headers)\n",
    "json_data = response.json()\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove existing prod subscription\n",
    "\n",
    "This code removes previous subscription that matches the name `German Credit Risk Model - Prod` as it is expected this subscription is created only via this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "for subscription in subscriptions_uids:\n",
    "    sub_name = ai_client.data_mart.subscriptions.get_details(subscription)['entity']['asset']['name']\n",
    "    if sub_name == PROD_MODEL_NAME:\n",
    "        ai_client.data_mart.subscriptions.delete(subscription)\n",
    "        print('Deleted existing subscription for', sub_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import configuration settings from pre-prod model\n",
    "\n",
    "With MRM we provide a important feature that lets you copy the configuration settings of your pre-production subscription to the production subscription. To try this out\n",
    "\n",
    "1. Navigate to Model Monitors view in Insights dashboard of OpenScale\n",
    "2. Click on the Add to dashboard\n",
    "3. Select the production model deployment from WML production machine learning provider and click on Configure\n",
    "4. In Selections saved dialog, click on Configure monitors\n",
    "5. Click on Import settings\n",
    "6. In the Import configuration settings dialog, choose the `German Credit Risk Model - PreProd` as the subscription from which you want to import the settings and click Configure\n",
    "7. In the Replace existing settings? dialog, click on Import\n",
    "\n",
    "All the configuration settings are now copied into the production subscription\n",
    "\n",
    "\n",
    "<b>Note: The next set of cells should be executed only after finishing the import settings from the OpenScale dashboard</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the production model so that we can trigger monitors\n",
    "\n",
    "Now that the production subscription is configured by copying the configuration, there would be schedules created for each of the monitors to run on a scheduled basis. \n",
    "Quality, Fairness and Mrm will run hourly. Drift will run once in three hours.\n",
    "\n",
    "For this demo purpose, we will trigger the monitors on-demand so that we can see the model summary dashboard without having to wait the entire hour. \n",
    "To do that lets first push some records in the Payload Logging table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "wml_client = WatsonMachineLearningAPIClient(PROD_WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_credit_risk_scoring_endpoint = None\n",
    "print(prod_deployment_uid)\n",
    "\n",
    "for deployment in wml_client.deployments.get_details()['resources']:\n",
    "    if prod_deployment_uid in deployment['metadata']['guid']:\n",
    "        prod_credit_risk_scoring_endpoint = deployment['entity']['scoring_url']\n",
    "        \n",
    "print(prod_credit_risk_scoring_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd_data.sample(n=400)\n",
    "df = df.drop(['Risk'], axis=1)\n",
    "fields = df.columns.tolist()\n",
    "values = df.values.tolist()\n",
    "\n",
    "payload_scoring = {\"fields\": fields,\"values\": values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_response = wml_client.deployments.score(prod_credit_risk_scoring_endpoint, payload_scoring)\n",
    "\n",
    "print('Single record scoring result:', '\\n fields:', scoring_response['fields'], '\\n values: ', scoring_response['values'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_subscription = ai_client.data_mart.subscriptions.get(name=PROD_DEPLOYMENT_NAME)\n",
    "prod_subscription.uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "prod_subscription.payload_logging.get_records_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch all monitor instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "MONITOR_INSTANCES_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/monitor_instances?target.target_id={1}&target.target_type=subscription\".format(WOS_GUID, prod_subscription.uid)\n",
    "print(MONITOR_INSTANCES_URL)\n",
    "\n",
    "response = requests.get(MONITOR_INSTANCES_URL, headers=headers)\n",
    "monitor_instances = response.json()[\"monitor_instances\"]\n",
    "\n",
    "drift_monitor_instance_id = None\n",
    "quality_monitor_instance_id = None\n",
    "mrm_monitor_instance_id = None\n",
    "\n",
    "if monitor_instances is not None:\n",
    "    for monitor_instance in monitor_instances:\n",
    "        if \"entity\" in monitor_instance and \"monitor_definition_id\" in monitor_instance[\"entity\"]:\n",
    "            monitor_name = monitor_instance[\"entity\"][\"monitor_definition_id\"]\n",
    "            if \"metadata\" in monitor_instance and \"id\" in monitor_instance[\"metadata\"]:\n",
    "                id = monitor_instance[\"metadata\"][\"id\"]\n",
    "                if monitor_name == \"drift\":\n",
    "                    drift_monitor_instance_id = id\n",
    "                elif monitor_name == \"quality\":\n",
    "                    quality_monitor_instance_id = id\n",
    "                elif monitor_name == \"mrm\":\n",
    "                    mrm_monitor_instance_id = id\n",
    "                    \n",
    "print(\"Quality monitor instance id - {0}\".format(quality_monitor_instance_id))\n",
    "print(\"Drift monitor instance id - {0}\".format(drift_monitor_instance_id))\n",
    "print(\"MRM monitor instance id - {0}\".format(mrm_monitor_instance_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get the monitoring run details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monitoring_run_details(monitor_instance_id, monitoring_run_id):\n",
    "    \n",
    "    headers = {}\n",
    "    headers[\"Content-Type\"] = \"application/json\"\n",
    "    headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "    \n",
    "    MONITORING_RUNS_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/monitor_instances/{1}/runs/{2}\".format(WOS_GUID, monitor_instance_id, monitoring_run_id)\n",
    "    response = requests.get(MONITORING_RUNS_URL, headers=headers, verify=False)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on-demand Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "if quality_monitor_instance_id is not None:\n",
    "    MONITOR_RUN_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/monitor_instances/{1}/runs\".format(WOS_GUID, quality_monitor_instance_id)\n",
    "    payload = {\n",
    "        \"triggered_by\": \"user\"\n",
    "    }\n",
    "    print(\"Triggering Quality computation with {}\".format(MONITOR_RUN_URL))\n",
    "    response = requests.post(MONITOR_RUN_URL, json=payload, headers=headers, verify=False)\n",
    "    json_data = response.json()\n",
    "    print()\n",
    "    print(json_data)\n",
    "    print()\n",
    "    if \"metadata\" in json_data and \"id\" in json_data[\"metadata\"]:\n",
    "        quality_monitoring_run_id = json_data[\"metadata\"][\"id\"]\n",
    "    print(\"Done triggering Quality computation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "quality_run_status = None\n",
    "while quality_run_status != 'finished':\n",
    "    monitoring_run_details = get_monitoring_run_details(quality_monitor_instance_id, quality_monitoring_run_id)\n",
    "    quality_run_status = monitoring_run_details[\"entity\"][\"status\"][\"state\"]\n",
    "    if quality_run_status == \"error\":\n",
    "        print(monitoring_run_details)\n",
    "        break\n",
    "    if quality_run_status != 'finished':\n",
    "        print(datetime.utcnow().strftime('%H:%M:%S'), quality_run_status)\n",
    "        time.sleep(10)\n",
    "print(quality_run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on-demand Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "if drift_monitor_instance_id is not None:\n",
    "    MONITOR_RUN_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/monitor_instances/{1}/runs\".format(WOS_GUID, drift_monitor_instance_id)\n",
    "    payload = {\n",
    "        \"triggered_by\": \"user\"\n",
    "    }\n",
    "    print(\"Triggering Drift computation with {}\".format(MONITOR_RUN_URL))\n",
    "    response = requests.post(MONITOR_RUN_URL, json=payload, headers=headers, verify=False)\n",
    "    json_data = response.json()\n",
    "    print()\n",
    "    print(json_data)\n",
    "    print()\n",
    "    if \"metadata\" in json_data and \"id\" in json_data[\"metadata\"]:\n",
    "        drift_monitoring_run_id = json_data[\"metadata\"][\"id\"]\n",
    "    print(\"Done triggering Drift computation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "drift_run_status = None\n",
    "while drift_run_status != 'finished':\n",
    "    monitoring_run_details = get_monitoring_run_details(drift_monitor_instance_id, drift_monitoring_run_id)\n",
    "    drift_run_status = monitoring_run_details[\"entity\"][\"status\"][\"state\"]\n",
    "    if drift_run_status == \"error\":\n",
    "        print(monitoring_run_details)\n",
    "        break\n",
    "    if drift_run_status != 'finished':\n",
    "        print(datetime.utcnow().strftime('%H:%M:%S'), drift_run_status)\n",
    "        time.sleep(10)\n",
    "print(drift_run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on-demand Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "FAIRNESS_RUNS_URL = WOS_CREDENTIALS[\"url\"] + \"/v1/fairness_monitoring/{0}/runs\".format(prod_subscription.uid)\n",
    "payload = {\n",
    "  \"binding_id\": binding_uid,\n",
    "  \"subscription_id\": prod_subscription.uid,\n",
    "  \"deployment_id\": prod_deployment_uid,\n",
    "  \"data_mart_id\": WOS_GUID\n",
    "}\n",
    "\n",
    "print(\"Triggering Fairness computation with {}\".format(FAIRNESS_RUNS_URL))\n",
    "response = requests.post(FAIRNESS_RUNS_URL, json=payload, headers=headers, verify=False)\n",
    "json_data = response.json()\n",
    "print()\n",
    "print(json_data)\n",
    "print()\n",
    "print(\"Done triggering Fairness computation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "fairness_run_status = None\n",
    "time.sleep(5)\n",
    "while fairness_run_status != 'FINISHED':\n",
    "    fairness_monitoring_details = prod_subscription.fairness_monitoring.get_details()\n",
    "    fairness_run_status = fairness_monitoring_details[\"parameters\"][\"run_status\"][prod_deployment_uid][\"run_status\"]\n",
    "    if fairness_run_status == \"FINISHED WITH ERRORS\":\n",
    "        print(fairness_monitoring_details)\n",
    "        break\n",
    "    if fairness_run_status != 'FINISHED':\n",
    "        print(datetime.utcnow().strftime('%H:%M:%S'), fairness_run_status)\n",
    "        time.sleep(10)\n",
    "print(fairness_run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on-demand MRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
    "\n",
    "if mrm_monitor_instance_id is not None:\n",
    "    MONITOR_RUN_URL = WOS_CREDENTIALS[\"url\"] + \"/openscale/{0}/v2/monitor_instances/{1}/runs\".format(WOS_GUID, mrm_monitor_instance_id)\n",
    "    payload = {\n",
    "        \"triggered_by\": \"user\"\n",
    "    }\n",
    "    print(\"Triggering MRM computation with {}\".format(MONITOR_RUN_URL))\n",
    "    response = requests.post(MONITOR_RUN_URL, json=payload, headers=headers, verify=False)\n",
    "    json_data = response.json()\n",
    "    print()\n",
    "    print(json_data)\n",
    "    print()\n",
    "    if \"metadata\" in json_data and \"id\" in json_data[\"metadata\"]:\n",
    "        mrm_monitoring_run_id = json_data[\"metadata\"][\"id\"]\n",
    "    print(\"Done triggering MRM computation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "mrm_run_status = None\n",
    "while mrm_run_status != 'finished':\n",
    "    monitoring_run_details = get_monitoring_run_details(mrm_monitor_instance_id, mrm_monitoring_run_id)\n",
    "    mrm_run_status = monitoring_run_details[\"entity\"][\"status\"][\"state\"]\n",
    "    if mrm_run_status == \"error\":\n",
    "        print(monitoring_run_details)\n",
    "        break\n",
    "    if mrm_run_status != 'finished':\n",
    "        print(datetime.utcnow().strftime('%H:%M:%S'), mrm_run_status)\n",
    "        time.sleep(10)\n",
    "print(mrm_run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refresh the model summary of the production subscription in the OpenScale dashboard\n",
    "\n",
    "This brings us to the end of this demo exercise. Thank you for trying it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
